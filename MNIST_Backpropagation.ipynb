{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Backpropagation.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhYPCy18tCCN"
      },
      "source": [
        "import sklearn\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.datasets import load_digits, fetch_openml\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from builtins import range\r\n",
        "from csv import reader\r\n",
        "from random import randrange\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import csv\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random\r\n",
        "import math\r\n",
        "random.seed(113)\r\n",
        "import warnings\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn import datasets\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "from tensorflow.examples.tutorials.mnist import input_data\r\n",
        "input_data.read_data_sets('C:/Users/mina/Desktop')\r\n",
        "\r\n",
        "from tensorflow.contrib.learn.python.learn.datasets.mnist import extract_images, extract_labels\r\n",
        "\r\n",
        "with open('C:/Users/mina/Desktop/train-images-idx3-ubyte.gz', 'rb') as f:\r\n",
        "  train_images = extract_images(f)\r\n",
        "with open('C:/Users/mina/Desktop/train-labels-idx1-ubyte.gz', 'rb') as f:\r\n",
        "  train_labels = extract_labels(f)\r\n",
        "\r\n",
        "with open('C:/Users/mina/Desktop/t10k-images-idx3-ubyte.gz', 'rb') as f:\r\n",
        "  test_images = extract_images(f)\r\n",
        "with open('C:/Users/mina/Desktop/t10k-labels-idx1-ubyte.gz', 'rb') as f:\r\n",
        "  test_labels = extract_labels(f)\r\n",
        "\r\n",
        "  train_labels.shape = (60000,1)\r\n",
        "  test_labels.shape = (10000,1)\r\n",
        "  \r\n",
        "#train_labels=train_labels.transpose()\r\n",
        "#test_labels=test_labels.transpose()\r\n",
        "\r\n",
        "print(train_labels.shape)\r\n",
        "print(test_labels.shape)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import keras\r\n",
        "\r\n",
        "# Flatten the images.\r\n",
        "train_images = train_images.reshape((-1, 784))\r\n",
        "test_images = test_images.reshape((-1, 784))\r\n",
        "\r\n",
        "no_of_different_labels =10\r\n",
        "\r\n",
        "print(train_images.shape) # (60000, 784)\r\n",
        "print(test_images.shape)  # (10000, 784)\r\n",
        "\r\n",
        "\r\n",
        "train_images = np.concatenate((train_labels, train_images),axis=1)\r\n",
        "test_images = np.concatenate((test_labels, test_images),axis=1)\r\n",
        "\r\n",
        "print(train_images.shape) # (60000, 785)\r\n",
        "print(test_images.shape)  # (10000, 785)\r\n",
        "train_images\r\n",
        "\r\n",
        "fac = 0.99 / 255\r\n",
        "train_imgs = np.asfarray(train_images[:, 1:]) * fac + 0.01\r\n",
        "test_imgs = np.asfarray(test_images[:, 1:]) * fac + 0.01\r\n",
        "train_labels = np.asfarray(train_images[:, :1])\r\n",
        "test_labels = np.asfarray(test_images[:, :1])\r\n",
        "\r\n",
        "pip install keras tensorflow numpy mnist\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "lr = np.arange(10)\r\n",
        "for label in range(10):\r\n",
        "    one_hot = (lr==label).astype(np.int)\r\n",
        "    print(\"label: \", label, \" in one-hot representation: \", one_hot)\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "lr = np.arange(no_of_different_labels)\r\n",
        "# transform labels into one hot representation\r\n",
        "train_labels_one_hot = (lr==train_labels).astype(np.float)\r\n",
        "test_labels_one_hot = (lr==test_labels).astype(np.float)\r\n",
        "# we don't want zeroes and ones in the labels neither:\r\n",
        "train_labels_one_hot[train_labels_one_hot==0] = 0.01\r\n",
        "train_labels_one_hot[train_labels_one_hot==1] = 0.99\r\n",
        "test_labels_one_hot[test_labels_one_hot==0] = 0.01\r\n",
        "test_labels_one_hot[test_labels_one_hot==1] = 0.99\r\n",
        "\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "    img = train_imgs[i].reshape((28,28))\r\n",
        "    plt.imshow(img, cmap=\"Greys\")\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "@np.vectorize\r\n",
        "def sigmoid(x):\r\n",
        "    return 1 / (1 + np.e ** -x)\r\n",
        "activation_function = sigmoid\r\n",
        "from scipy.stats import truncnorm\r\n",
        "def truncated_normal(mean=0, sd=1, low=0, upp=10):\r\n",
        "    return truncnorm((low - mean) / sd, \r\n",
        "                     (upp - mean) / sd, \r\n",
        "                     loc=mean, \r\n",
        "                     scale=sd)\r\n",
        "class NeuralNetwork:\r\n",
        "    \r\n",
        "    def __init__(self, \r\n",
        "                 no_of_in_nodes, \r\n",
        "                 no_of_out_nodes, \r\n",
        "                 no_of_hidden_nodes,\r\n",
        "                 learning_rate):\r\n",
        "        self.no_of_in_nodes = no_of_in_nodes\r\n",
        "        self.no_of_out_nodes = no_of_out_nodes\r\n",
        "        self.no_of_hidden_nodes = no_of_hidden_nodes\r\n",
        "        self.learning_rate = learning_rate \r\n",
        "        self.create_weight_matrices()\r\n",
        "        \r\n",
        "    def create_weight_matrices(self):\r\n",
        "        \"\"\" A method to initialize the weight matrices of the neural network\"\"\"\r\n",
        "        rad = 1 / np.sqrt(self.no_of_in_nodes)\r\n",
        "        X = truncated_normal(mean=0, \r\n",
        "                             sd=1, \r\n",
        "                             low=-rad, \r\n",
        "                             upp=rad)\r\n",
        "        self.wih = X.rvs((self.no_of_hidden_nodes, \r\n",
        "                                       self.no_of_in_nodes))\r\n",
        "        rad = 1 / np.sqrt(self.no_of_hidden_nodes)\r\n",
        "        X = truncated_normal(mean=0, \r\n",
        "                             sd=1, \r\n",
        "                             low=-rad, \r\n",
        "                             upp=rad)\r\n",
        "        self.who = X.rvs((self.no_of_out_nodes, \r\n",
        "                                        self.no_of_hidden_nodes))\r\n",
        "        \r\n",
        "    \r\n",
        "    def train_single(self, input_vector, target_vector):\r\n",
        "        \"\"\"\r\n",
        "        input_vector and target_vector can be tuple, \r\n",
        "        list or ndarray\r\n",
        "        \"\"\"\r\n",
        "        \r\n",
        "        output_vectors = []\r\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\r\n",
        "        target_vector = np.array(target_vector, ndmin=2).T\r\n",
        "        \r\n",
        "        output_vector1 = np.dot(self.wih, \r\n",
        "                                input_vector)\r\n",
        "        output_hidden = activation_function(output_vector1)\r\n",
        "        \r\n",
        "        output_vector2 = np.dot(self.who, \r\n",
        "                                output_hidden)\r\n",
        "        output_network = activation_function(output_vector2)\r\n",
        "        \r\n",
        "        output_errors = target_vector - output_network\r\n",
        "        # update the weights:\r\n",
        "        tmp = output_errors * output_network * \\\r\n",
        "              (1.0 - output_network)     \r\n",
        "        tmp = self.learning_rate  * np.dot(tmp, \r\n",
        "                                           output_hidden.T)\r\n",
        "        self.who += tmp\r\n",
        "        \r\n",
        "        who_old = 0\r\n",
        "        wih_old = 0\r\n",
        "        if(len(self.intermediate_weights) > 0):\r\n",
        "            who_old = self.intermediate_weights[-1][1]\r\n",
        "            wih_old = self.intermediate_weights[-1][0]\r\n",
        "        \r\n",
        "        # Adding the momentum value for who update\r\n",
        "        self.who += who_old * 0.5\r\n",
        "        \r\n",
        "        # calculate hidden errors:\r\n",
        "        hidden_errors = np.dot(self.who.T, \r\n",
        "                               output_errors)\r\n",
        "        # update the weights:\r\n",
        "        tmp = hidden_errors * output_hidden * (1.0 - output_hidden)\r\n",
        "        self.wih += self.learning_rate * np.dot(tmp, input_vector.T)\r\n",
        "        \r\n",
        "        # Adding the momentum value for wih update\r\n",
        "        self.wih += wih_old * 0.5\r\n",
        "        \r\n",
        "    def train(self, data_array, \r\n",
        "              labels_one_hot_array,\r\n",
        "              epochs=1,\r\n",
        "              intermediate_results=False):\r\n",
        "        \r\n",
        "        for epoch in range(epochs):\r\n",
        "            self.intermediate_weights = []\r\n",
        "            print(\"*\", end=\"\")\r\n",
        "            for i in range(len(data_array)):\r\n",
        "                self.train_single(data_array[i], \r\n",
        "                                  labels_one_hot_array[i])\r\n",
        "            if intermediate_results:\r\n",
        "                self.intermediate_weights.append((self.wih.copy(), \r\n",
        "                                             self.who.copy()))\r\n",
        "        return self.intermediate_weights        \r\n",
        "            \r\n",
        "\r\n",
        "        \r\n",
        "    def run(self, input_vector):\r\n",
        "        # input_vector can be tuple, list or ndarray\r\n",
        "        input_vector = np.array(input_vector, ndmin=2).T\r\n",
        "        output_vector = np.dot(self.wih, \r\n",
        "                               input_vector)\r\n",
        "        output_vector = activation_function(output_vector)\r\n",
        "        \r\n",
        "        output_vector = np.dot(self.who, \r\n",
        "                               output_vector)\r\n",
        "        output_vector = activation_function(output_vector)\r\n",
        "    \r\n",
        "        return output_vector\r\n",
        "            \r\n",
        "    def confusion_matrix(self, data_array, labels):\r\n",
        "        cm = np.zeros((10, 10), int)\r\n",
        "        for i in range(len(data_array)):\r\n",
        "            res = self.run(data_array[i])\r\n",
        "            res_max = res.argmax()\r\n",
        "            target = labels[i][0]\r\n",
        "            cm[res_max, int(target)] += 1\r\n",
        "        return cm    \r\n",
        "    def precision(self, label, confusion_matrix):\r\n",
        "        col = confusion_matrix[:, label]\r\n",
        "        return confusion_matrix[label, label] / col.sum()\r\n",
        "    \r\n",
        "    def recall(self, label, confusion_matrix):\r\n",
        "        row = confusion_matrix[label, :]\r\n",
        "        return confusion_matrix[label, label] / row.sum()\r\n",
        "        \r\n",
        "    \r\n",
        "    def evaluate(self, data, labels):\r\n",
        "        corrects, wrongs = 0, 0\r\n",
        "        for i in range(len(data)):\r\n",
        "            res = self.run(data[i])\r\n",
        "            res_max = res.argmax()\r\n",
        "            if res_max == labels[i]:\r\n",
        "                corrects += 1\r\n",
        "            else:\r\n",
        "                wrongs += 1\r\n",
        "        return corrects, wrongs\r\n",
        "            \r\n",
        "\r\n",
        "epochs = 10\r\n",
        "ANN = NeuralNetwork(no_of_in_nodes = 784, \r\n",
        "                               no_of_out_nodes = 10, \r\n",
        "                               no_of_hidden_nodes = 50,\r\n",
        "                               learning_rate = 0.1)\r\n",
        "    \r\n",
        "    \r\n",
        " \r\n",
        "weights = ANN.train(train_imgs, \r\n",
        "                    train_labels_one_hot, \r\n",
        "                    epochs=epochs, \r\n",
        "                    intermediate_results=True)\r\n",
        "\r\n",
        "cm = ANN.confusion_matrix(train_imgs, train_labels)\r\n",
        "        \r\n",
        "print(ANN.run(train_imgs[i]))\r\n",
        "\r\n",
        "print(cm)\r\n",
        "corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\r\n",
        "print(\"accruracy train: \", corrects / ( corrects + wrongs))\r\n",
        "corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\r\n",
        "print(\"accruracy: test\", corrects / ( corrects + wrongs))\r\n",
        "cm = ANN.confusion_matrix(train_imgs, train_labels)\r\n",
        "print(cm)\r\n",
        "for i in range(10):\r\n",
        "    print(\"digit: \", i, \"precision: \", ANN.precision(i, cm), \"recall: \", ANN.recall(i, cm))\r\n",
        "\r\n",
        "#from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "#print(confusion_matrix(train_imgs, test_imgs))\r\n",
        "\r\n",
        "for i in range(epochs):  \r\n",
        "    print(\"epoch: \", i)\r\n",
        "    ANN.wih = weights[i][0]\r\n",
        "    ANN.who = weights[i][1]\r\n",
        "   \r\n",
        "    corrects, wrongs = ANN.evaluate(train_imgs, train_labels)\r\n",
        "    print(\"accruracy train: \", corrects / ( corrects + wrongs))\r\n",
        "    corrects, wrongs = ANN.evaluate(test_imgs, test_labels)\r\n",
        "    print(\"accruracy test:\", corrects / ( corrects + wrongs))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}