from sklearn.datasets import load_digits, fetch_openml
from sklearn.model_selection import train_test_split
from builtins import range
from csv import reader
from random import randrange
import numpy as np
import pandas as pd 
import csv
import random
import math
random.seed(113)
import warnings
from sklearn.metrics import classification_report
from sklearn import datasets
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
%matplotlib inline

from tensorflow.examples.tutorials.mnist import input_data
input_data.read_data_sets('C:/Assignment2')


from tensorflow.contrib.learn.python.learn.datasets.mnist import extract_images, extract_labels

with open('C:/Assignment2/train-images-idx3-ubyte.gz', 'rb') as f:
  train_images = extract_images(f)
with open('C:/Assignment2/train-labels-idx1-ubyte.gz', 'rb') as f:
  train_labels = extract_labels(f)

with open('C:/Assignment2/t10k-images-idx3-ubyte.gz', 'rb') as f:
  test_images = extract_images(f)
with open('C:/Assignment2/t10k-labels-idx1-ubyte.gz', 'rb') as f:
  test_labels = extract_labels(f)

import numpy as np
import keras
import mnist

train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Flatten the images.
train_images = train_images.reshape((-1, 784))
test_images = test_images.reshape((-1, 784))

print(train_images.shape) # (60000, 784)
print(test_images.shape)  # (10000, 784)

pip install keras tensorflow numpy mnist

import numpy as np
import mnist
import numpy as np
import mnist
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical

train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Flatten the images.
train_images = train_images.reshape((-1, 784))
test_images = test_images.reshape((-1, 784))

print(train_images.shape) # (60000, 784)
print(test_images.shape)  # (10000, 784)

# Build the model.
model = Sequential([
  Dense(64, activation='relu', input_shape=(784,)),
  Dense(64, activation='relu'),
  Dense(10, activation='softmax'),
])

# Compile the model.
model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)
# Train the model.
model.fit(
  train_images,
  to_categorical(train_labels),
  epochs=5,
  batch_size=32,
)


#------------------------------result------------------------------------

(60000, 784)
(10000, 784)
Epoch 1/5
60000/60000 [==============================] - 4s 63us/step - loss: 0.3576 - acc: 0.8919
Epoch 2/5
60000/60000 [==============================] - 4s 63us/step - loss: 0.1785 - acc: 0.9443
Epoch 3/5
60000/60000 [==============================] - 4s 64us/step - loss: 0.1379 - acc: 0.9578
Epoch 4/5
60000/60000 [==============================] - 3s 58us/step - loss: 0.1176 - acc: 0.9636
Epoch 5/5
60000/60000 [==============================] - 4s 61us/step - loss: 0.1029 - acc: 0.9675

<keras.callbacks.History at 0x7f3d472f62e8>
