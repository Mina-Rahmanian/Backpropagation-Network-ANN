{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backpropagation-Oct11-2019.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYZgghkz1zdc"
      },
      "source": [
        "MINA RAHMANIAN\n",
        "\n",
        "\n",
        "BACKPROPAGATION NETWORK\n",
        "\n",
        "2019-10-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFVROMEq2nXH"
      },
      "source": [
        "==========================================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb5yx2RM2pFu"
      },
      "source": [
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk7knb2B1xRc"
      },
      "source": [
        "import numpy\n",
        "import gzip\n",
        "import pickle\n",
        "import struct\n",
        "import pylab\n",
        "import random\n",
        "from copy import copy\n",
        "from sklearn.datasets import load_digits, fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from builtins import range\n",
        "from csv import reader\n",
        "from random import randrange\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import csv\n",
        "import random\n",
        "import math\n",
        "random.seed(113)\n",
        "import warnings\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSzmS6rW2xbb"
      },
      "source": [
        "Network Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b137wKI_8R2"
      },
      "source": [
        "# this is the main directory for importing all files and also exporting results\n",
        "mainDirPath = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtclGvrLXHbY"
      },
      "source": [
        "class Network:\n",
        "\t\n",
        "  # constructor\n",
        "  # two parameters are required for constructor; one is the array of dimentions for \n",
        "  # all layers (input, hidden layers, output respectively); the other one is a flag indicating\n",
        "  # if the user wants to use the already trained wigthing factors and biosed values or he wants to train the \n",
        "  # network from scratch.\n",
        "\tdef __init__(self, layerDimensions, shouldUsedExistingTrainedValues = False):\n",
        "\t\t\n",
        "\t\tself._layerDimensions = layerDimensions\n",
        "\t\tself.nLayers = len(layerDimensions)\n",
        "\t\tself._weightingFactorList = []\n",
        "\t\tself._biasValueList = []\n",
        "\t\t\n",
        "\t\tif shouldUsedExistingTrainedValues == True:\n",
        "\t\t\twith open(\"C:/Assignment2/weights\", \"rb\") as file_weights:\n",
        "\t\t\t\tmon_pickler = pickle.Unpickler(file_weights)\n",
        "\t\t\t\tself._weightingFactorList = mon_pickler.load()\n",
        "\t\t\t\n",
        "\t\t\twith open(\"C:/Assignment2/biases\", \"rb\") as file_biases:\n",
        "\t\t\t\tmon_pickler = pickle.Unpickler(file_biases)\n",
        "\t\t\t\tself._biasValueList = mon_pickler.load()\n",
        "\t\t\n",
        "\t\telse:\n",
        "\t\t\ti = 1\n",
        "\t\t\twhile i < self.nLayers:\n",
        "\t\t\t\tself._number_current = self._layerDimensions[i]\n",
        "\t\t\t\tself._number_previous = self._layerDimensions[(i-1)]\n",
        "        \n",
        "        # use random values intially\n",
        "\t\t\t\twighting = numpy.random.normal(0, 1, (self._number_current, self._number_previous))\n",
        "\t\t\t\tbiais = numpy.random.normal(0, 1, self._number_current) \n",
        "\t\t\t\tself._weightingFactorList += [wighting]\n",
        "\t\t\t\tself._biasValueList += [biais]\n",
        "\t\t\t\ti += 1\n",
        "\t\t\t\t\t\t\n",
        "\tdef _get_poids(self):\n",
        "\t\treturn(self._weightingFactorList)\n",
        "\t\t\n",
        "\tdef _get_biais(self):\n",
        "\t\treturn(self._biasValueList)\n",
        "\t\t\n",
        "\t#feed forward method\t\n",
        "\tdef _feedforward(self, input):\n",
        "\t\tinp = numpy.ndarray.flatten((1/255)*input) \n",
        "\t\tN = len(self._weightingFactorList)\n",
        "\t\ti = 0\n",
        "\t\t\n",
        "\t\twhile i < N:\n",
        "\t\t\tinp = numpy.dot(self._weightingFactorList[i], inp) + self._biasValueList[i]\n",
        "\t\t\tinp = sigmoid_vec(inp)\n",
        "\t\t\ti +=1\n",
        "\t\t\t\n",
        "\t\treturn inp\n",
        "\t\t\n",
        "\t\n",
        "  # Using the testing data, this method display the acuracy of network prediction\n",
        "  # according to its trained values.\n",
        "\tdef _test(self, data):\n",
        "\t\tif len(data[0]) != len(data[1]):\n",
        "\t\t\traise Exception(\"No of images and number of labels are not equal !\")\n",
        "\t\telse:\n",
        "\t\t\tN = len(data[0])\n",
        "\t\t\tnumber_success = 0\n",
        "\t\t\ti = 0\n",
        "\t\t\twhile i < N:\n",
        "\t\t\t\tresult = self._feedforward(data[0][i])\n",
        "\t\t\t\tnumber = result.argmax()\n",
        "\t\t\t\tif number == data[1][i]:\n",
        "\t\t\t\t\tnumber_success += 1\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tif i% 100 == 0:\n",
        "\t\t\t\t\tprint(\"# Tested  {}\".format(i))\n",
        "\t\t\t\t\t\n",
        "\t\t\t\ti += 1\n",
        "\t\t\t\t\t\n",
        "\t\t\tprint(\"Accuracy : {} %\".format(number_success/N))\n",
        "\t\t\t\n",
        "\t\t\treturn number_success/N\n",
        "\t\n",
        "  # method of back propagation during the training process\n",
        "\tdef _backpropagation(self, input, true_output):\n",
        "\t\tinp = input\n",
        "\t\tN = len(self._weightingFactorList)\n",
        "\t\ti = 0\n",
        "\t\tlist_wsum = []\n",
        "\t\tlist_outputs = [input]\n",
        "\t\t\n",
        "\t\twhile i < N:\n",
        "\t\t\tinp = numpy.dot(self._weightingFactorList[i], inp) + self._biasValueList[i]\n",
        "\t\t\tlist_wsum += [inp]\n",
        "\t\t\tinp = sigmoid_vec(inp)\n",
        "\t\t\tlist_outputs += [inp]\n",
        "\t\t\ti += 1\n",
        "\t\t\t\n",
        "\t\tlist_vec_errors = [(inp - true_output)*sigmoid_derivative_vec(list_wsum[(N-1)])]\n",
        "\t\ti = 1\n",
        "\t\twhile i < N:\n",
        "\t\t\ttransp = numpy.transpose(self._weightingFactorList[(N-i)])\n",
        "\t\t\terror = numpy.dot(transp, list_vec_errors[0])*sigmoid_derivative_vec(list_wsum[(N-i-1)])\n",
        "\t\t\tlist_vec_errors = [error] + list_vec_errors\n",
        "\t\t\ti += 1\n",
        "\t\t\n",
        "\n",
        "\t\tlist_part_deriv = []\n",
        "\t\tlist_part_bias = []\n",
        "\t\tl = 0\n",
        "\t\twhile l < N:\n",
        "\t\t\tmatrice = copy(self._weightingFactorList[l])\n",
        "\t\t\tbias = copy(self._biasValueList[l])\n",
        "\t\t\tfor i in range(0, len(matrice[:, 1])):\n",
        "\t\t\t\tfor j in range(0, len(matrice[1, :])):\n",
        "\t\t\t\t\tmatrice[i, j] = list_outputs[l][j]*list_vec_errors[l][i]\n",
        "\t\t\t\t\n",
        "\t\t\t\tbias[i] = list_vec_errors[l][i]\n",
        "\t\t\t\t\n",
        "\t\t\tlist_part_deriv += [matrice]\n",
        "\t\t\tlist_part_bias += [bias]\n",
        "\t\t\tl += 1\n",
        "\t\t\t\n",
        "\t\t\n",
        "\t\treturn (list_part_deriv, list_part_bias)\n",
        "\t\t\n",
        "\t# the minibactch data are getting updated in this method\t\n",
        "\tdef _update_mini_batch(self, list_images, list_labels, rate):\n",
        "\t\tN = len(list_images)\n",
        "\t\tNb_layers = self.nLayers\n",
        "\t\tif N != len(list_labels):\n",
        "\t\t\traise Exception(\"Number of images and labels are not equal!\")\n",
        "\t\telse:\n",
        "\t\t\tlist_weight = self._weightingFactorList.copy()\n",
        "\t\t\tlist_bias = self._biasValueList.copy()\n",
        "\t\t\t\t\n",
        "\t\t\ti = 0\n",
        "\t\t\twhile i < N:\n",
        "\t\t\t\tdesired_output = numpy.zeros(self._layerDimensions[-1])\n",
        "\t\t\t\tdesired_output[list_labels[i]] = 1\n",
        "\t\t\t\tweightings, bias = self._backpropagation(numpy.ndarray.flatten((1/255)*list_images[i]), desired_output)\n",
        "\t\t\t\tfor l, elt in  enumerate(weightings):\n",
        "\t\t\t\t\tlist_weight[l] += (-rate/N)*elt\n",
        "\t\t\t\t\tlist_bias[l] += (-rate/N)*bias[l]\n",
        "\t\t\t\t\t\n",
        "\t\t\t\ti += 1\n",
        "\t\t\t\n",
        "\t\t\tself._weightingFactorList = list_weight.copy()\n",
        "\t\t\tself._biasValueList = list_bias.copy()\n",
        "\t\n",
        "\t\t\n",
        "\t\t\n",
        "\tdef _train(self, training_set, number_epochs, size_mini_batch, rate):\n",
        "\t\tif len(training_set[0])% size_mini_batch != 0:\n",
        "\t\t\traise Exception(\"Size of training set is not a multiple of mini-batch size !\")\n",
        "\t\telse:\n",
        "\t\t\ttraining_images = training_set[0]\n",
        "\t\t\ttraining_labels = training_set[1]\n",
        "\t\t\n",
        "\t\t\ti = 0\n",
        "\t\t\twhile i < number_epochs:\n",
        "\t\t\t  print(\"Epoch {} Started\".format(i+1))\n",
        "\t\t\t  tempImg = copy(training_images)\n",
        "\t\t\t  tempLabel = copy(training_labels)\n",
        "\t\t\t  j = 0\n",
        "\t\t\t  m = len(training_set[0])/size_mini_batch\n",
        "\t\t\t  print(m)\n",
        "\t\t\t  while j < m:\n",
        "\t\t\t    mini_batch_images = []\n",
        "\t\t\t    mini_batch_labels = []\n",
        "\t\t\t    l = 0\n",
        "\t\t\t    while l < size_mini_batch:\n",
        "\t\t\t      random_index = random.randint(0, (len(tempImg)-1))\n",
        "\t\t\t      mini_batch_images += [tempImg[random_index]]\n",
        "\t\t\t      mini_batch_labels += [tempLabel[random_index]]\n",
        "\t\t\t      del tempImg[random_index]\n",
        "\t\t\t      del tempLabel[random_index]\n",
        "\t\t\t      l += 1\n",
        "\t\t\t      self._update_mini_batch(mini_batch_images, mini_batch_labels, rate)\n",
        "\t\t\t    j +=1\n",
        "\t\t\t\t\t\n",
        "\t\t\t  print(\"Epoch {} complete\".format(i+1))\n",
        "\t\t\t  i += 1\n",
        "\t\t\t\t\n",
        "\t\t\twith open(\"C:/mina/weights\", \"wb\") as fichier_weights:\n",
        "\t\t\t\tmy_pickler = pickle.Pickler(fichier_weights)\n",
        "\t\t\t\tmy_pickler.dump(self._weightingFactorList)\n",
        "\t\t\t\t\n",
        "\t\t\twith open(\"C:/mina/biases\", \"wb\") as fichier_biases:\n",
        "\t\t\t\tmy_pickler = pickle.Pickler(fichier_biases)\n",
        "\t\t\t\tmy_pickler.dump(self._biasValueList)\n",
        "\t\t\t\t\n",
        "\tliste_weightings = property(_get_poids)\n",
        "  \n",
        "  \n",
        "#sigmoid function calculation method \n",
        "def sigmoid(z):\n",
        "\treturn(1.0/(1.0+numpy.exp(-z)))\n",
        "\t\n",
        "sigmoid_vec = numpy.vectorize(sigmoid)\n",
        "\t\t\t\n",
        "#sigmoid function derivative calculation method \n",
        "def sigmoid_derivative(z):\n",
        "\treturn sigmoid(z)*(1-sigmoid(z))\n",
        "\t\n",
        "sigmoid_derivative_vec = numpy.vectorize(sigmoid_derivative)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoNkaOzIXOfK"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "input_data.read_data_sets('C:/mina')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csoKOWqhrpBr"
      },
      "source": [
        "# method for loading training data\n",
        "\n",
        "def load_training_data():\n",
        "\ttrain = gzip.open(\"C:/mina/train-images-idx3-ubyte.gz\", \"rb\")\n",
        "\tlabels = gzip.open(\"C:/mina/train-labels-idx1-ubyte.gz\", \"rb\")\n",
        "\t\n",
        "\ttrain.read(4)\n",
        "\tlabels.read(4)\n",
        "\t\t\n",
        "\tnumber_images = train.read(4)\n",
        "\tnumber_images = struct.unpack(\">I\", number_images)[0]\n",
        "\t\t\n",
        "\trows = train.read(4)\n",
        "\trows = struct.unpack(\">I\", rows)[0]\n",
        "\t\t\n",
        "\tcols = train.read(4)\n",
        "\tcols = struct.unpack(\">I\", cols)[0]\n",
        "\t\t\n",
        "\tnumber_labels = labels.read(4)\n",
        "\tnumber_labels = struct.unpack(\">I\", number_labels)[0]\n",
        "\t\n",
        "\timage_list = []\n",
        "\tlabel_list = []\n",
        "\tif number_images != number_labels:\n",
        "\t\traise Exception(\"The number of labels doesn't match with the number of images\")\n",
        "\telse:\n",
        "\t\tfor l in range(number_labels):\n",
        "\t\t\tif l % 1000 == 0:\n",
        "\t\t\t\tprint(\"# loaded data :{}\".format(l))\n",
        "\t\t\t\t\n",
        "\t\t\tmat = numpy.zeros((rows, cols), dtype = numpy.uint8)\n",
        "\t\t\tfor i in range(rows):\n",
        "\t\t\t\tfor j in range(cols):\n",
        "\t\t\t\t\tpixel = train.read(1)\n",
        "\t\t\t\t\tpixel = struct.unpack(\">B\", pixel)[0]\n",
        "\t\t\t\t\tmat[i][j] = pixel\n",
        "\t\t\t\t\t\n",
        "\t\t\t\n",
        "\t\t\timage_list += [mat]\n",
        "\t\t\tlab = labels.read(1)\n",
        "\t\t\tlab = struct.unpack(\">B\", lab)[0]\n",
        "\t\t\tlabel_list += [lab]\n",
        "\t\t\n",
        "\t\n",
        "\ttrain.close()\n",
        "\tlabels.close()\n",
        "\t\t\n",
        "\treturn ([image_list, label_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCEQyGCEdfAO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClM3gmmmXSQI"
      },
      "source": [
        "# method for loading tes data\n",
        "\n",
        "def load_test_data():\n",
        "\ttest = gzip.open(\"C:/mina/t10k-images-idx3-ubyte.gz\", \"rb\")\n",
        "\tlabels = gzip.open(\"C:/mina/t10k-labels-idx1-ubyte.gz\", \"rb\")\n",
        "\t\n",
        "\ttest.read(4)\n",
        "\tlabels.read(4)\n",
        "\t\t\n",
        "\tnumber_images = test.read(4)\n",
        "\tnumber_images = struct.unpack(\">I\", number_images)[0]\n",
        "\t\t\n",
        "\trows = test.read(4)\n",
        "\trows = struct.unpack(\">I\", rows)[0]\n",
        "\t\t\n",
        "\tcols = test.read(4)\n",
        "\tcols = struct.unpack(\">I\", cols)[0]\n",
        "\t\t\n",
        "\tnumber_labels = labels.read(4)\n",
        "\tnumber_labels = struct.unpack(\">I\", number_labels)[0]\n",
        "\t\n",
        "\timage_list = []\n",
        "\tlabel_list = []\n",
        "\tif number_images != number_labels:\n",
        "\t\traise Exception(\"The number of labels are not equal to the number of images\")\n",
        "\telse:\n",
        "\t\tfor l in range(number_labels):\n",
        "\t\t\tif l % 1000 == 0:\n",
        "\t\t\t\tprint(\"# loaded data :{}\".format(l))\n",
        "\t\t\t\t\n",
        "\t\t\tmat = numpy.zeros((rows, cols), dtype = numpy.uint8)\n",
        "\t\t\tfor i in range(rows):\n",
        "\t\t\t\tfor j in range(cols):\n",
        "\t\t\t\t\tpixel = test.read(1)\n",
        "\t\t\t\t\tpixel = struct.unpack(\">B\", pixel)[0]\n",
        "\t\t\t\t\tmat[i][j] = pixel\n",
        "\t\t\t\t\t\n",
        "\t\t\t#view(mat)\n",
        "\t\t\timage_list += [mat]\n",
        "\t\t\tlab = labels.read(1)\n",
        "\t\t\tlab = struct.unpack(\">B\", lab)[0]\n",
        "\t\t\tlabel_list += [lab]\n",
        "\t\t\n",
        "\t\n",
        "\ttest.close()\n",
        "\tlabels.close()\n",
        "\t\t\n",
        "\treturn ([image_list, label_list])\t\n",
        "\n",
        "# auxillary method to display the image if required\t\n",
        "def view(image, label=\"\"):\n",
        "\t#print(\"Number : {}\".format(label))\n",
        "\tpylab.imshow(image, cmap = pylab.cm.gray)\n",
        "\tpylab.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-dVNDUMXVqC"
      },
      "source": [
        "# 1. load the training data if you want to train the model from scratch.\n",
        "trainingData = load_training_data()\n",
        "\n",
        "# 2. construct a network \n",
        "inputLayerSize = 28 * 28\n",
        "hiddenLayerSize = 30\n",
        "outputLayerSize = 10\n",
        "\n",
        "shouldUsedExistingTrainedValues = False\n",
        " \n",
        "net = Network([inputLayerSize, hiddenLayerSize, outputLayerSize], shouldUsedExistingTrainedValues)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FXlo_q2Lzw5"
      },
      "source": [
        "# 3. (optional)\n",
        "# this section will override the previously trained values\n",
        "# NOTE: do not run if you want to reuse the trained values\n",
        "\n",
        "nEpoch = 10\n",
        "nBatch = 100\n",
        "learningRate = 0.4\n",
        "\n",
        "net._train(trainingData, nEpoch, nBatch, learningRate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTDHc3h8Ixsy"
      },
      "source": [
        "# 4. load the test data\n",
        "testData = load_test_data()\n",
        "\n",
        "# 5. test the network predition acuracy\n",
        "result = net._test(testData)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
